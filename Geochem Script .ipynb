{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Data Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will upload your data to be used for analysis. Before uploading the data please ensure that you have installed Anaconda on your computer. If you have not already done so, follow the instructions here:\n",
    "https://www.anaconda.com/products/individual\n",
    "\n",
    "Alternatively, if you would like to proceed without installing Anaconda then please ensure the following packages are installed: tkinter, pandas, numpy, matlibplot.\n",
    "\n",
    "Once Anaconda is installed, download the .ipynb file and open a jupyter notebook on your computer. Next, open the .ipynb in the jupyter notebook. At this point, you are ready to run the geochem script!\n",
    "\n",
    "When you are ready to upload your data, click on the cell below and press the run button. The data must be one of the following data types: xls, xlsx, xlsm, xlsb, csv, and odf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Creating prompt for user to select file using tkinter package.\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "file_path = filedialog.askopenfilename()\n",
    "\n",
    "# Allowable excel file types for pandas dataframe.\n",
    "file_types_excel = ['xls','xlsx','xlsm','xlsb','odf']\n",
    "\n",
    "# Check if file is an excel file or an csv.\n",
    "if file_path[-3:] in file_types_excel or file_path[-4:] in file_types_excel:\n",
    "    df = pd.read_excel(file_path)\n",
    "    print('Excel file uploaded successfully!')\n",
    " \n",
    "elif file_path[-3:] == 'csv':\n",
    "    df = pd.read_csv(file_path, low_memory = False)\n",
    "    print('CSV file uploaded successfully!')\n",
    "    \n",
    "else:\n",
    "    print(\"File type not supported. xls, xlsx, xlsm, xlsb, csv, and odf files are accepted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Numerical Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the uploaded data will be transformed in the following ways:\n",
    "\n",
    "Negative values --> Invert sign and divide value by 2. <br>\n",
    "Zero values     --> Replace with a null value (NaN). <br>\n",
    "Less than sign(e.g. <50) --> Remove < and divide value by 2. <br> \n",
    "Text values     --> Remove text value and replace with null (NaN). <br>\n",
    "\n",
    "\n",
    "Run the module below to enter the units of the columns you would like to transform. <br> Be aware that the program is case sensitive. <br>\n",
    "Example: Entering ppb will transform all columns with ppb in the title (au_ppb_ano, al_ppb_ano, b_ppb_ano would all be transformed.)  \n",
    "\n",
    "Alternatively, each column could be marked with a character only used in those columns. In this case, just enter the identifying character. <br>\n",
    "Example: Put || at the end of each column to be transformed (au_ppb_ano||, al_ppm_ano||, etc.) \n",
    "In this case, enter || in the module below. \n",
    "\n",
    "Lastly, type end when finished. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = [] \n",
    "cur_in = ''\n",
    "\n",
    "while True:\n",
    "    cur_in = input('Enter column marker:')\n",
    "    if cur_in == 'end':\n",
    "        break\n",
    "    else:\n",
    "        data_types.append(cur_in)\n",
    "\n",
    "print(\"Columns to be transformed:{}\".format(data_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the module below to transform the selected columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refresh df so that this module may be run multiple times.\n",
    "#if file_path[-3:] in file_types_excel or file_path[-4:] in file_types_excel:\n",
    "#    df = pd.read_excel(file_path, low_memory = False)\n",
    "    \n",
    "#elif file_path[-3:] == 'csv':\n",
    "#    df = pd.read_csv(file_path, low_memory = False)\n",
    "\n",
    "# Adding comment row to the dataframe, df, as row n+1. The format of the comments list is:\n",
    "# [1.{# of instances}--Negative value, replaced with 1/2 Detection limit ---> NR\n",
    "#  2.{# of instances}--Zero Changed to null   ---> ZR\n",
    "#  3.{# of instances}--Less than (<) replaced with 1/2 Detection Limit ---> LTR\n",
    "#  4.{# of instances}--Text replaced with null] ---> TR\n",
    "# First, the number of instances will be collected, then the text will be added at the end. \n",
    "commentsdf = pd.DataFrame([[[0,0,0,0] for i in range(df.shape[1])]], columns = df.columns)\n",
    "df = df.append(commentsdf, ignore_index = True)\n",
    "\n",
    "# Function to check in current column is in the data types to be transformed\n",
    "def data_bool(data_types_list, column):\n",
    "    \n",
    "    for i in range(len(data_types_list)):\n",
    "        if data_types_list[i] in column:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    " \n",
    "print('Transforming... ')\n",
    "\n",
    "neg_num = [-9,-99,-999,-9999,-99999]\n",
    "\n",
    "#Search all columns. If column, col, is in data_types then transform the column.\n",
    "for col in df.columns:\n",
    "    if data_bool(data_types, col):\n",
    "        for i in range(df.shape[0]-1):\n",
    "            \n",
    "            \n",
    "            if str(df.at[i, col])[0] == '-' and str(df.at[i, col])[-1] == '9' or df.at[i, col] in neg_num:\n",
    "    \n",
    "                df.at[i, col] = np.NaN\n",
    "            \n",
    "            #check if data point is zero. Increment the ZR counter one. \n",
    "            if df.at[i, col] == 0:\n",
    "                df.at[i, col] = np.NaN\n",
    "                df.at[df.shape[0]-1, col][1] += 1\n",
    "\n",
    "            #check if data point begins with the less than symbol. Must use try as int's are unscriptable. \n",
    "            #increment the LTR counter one. \n",
    "            try:\n",
    "                if df.at[i,col][0] == '<':\n",
    "                    df.at[i,col] = int(df.at[i,col].replace('<',''))/2\n",
    "                    df.at[df.shape[0]-1, col][2] += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            #check if data point is negative. Use try because a string can't be compared with <. \n",
    "            #increment the NR counter.\n",
    "            try:\n",
    "                if df.at[i,col] < 0:\n",
    "                    df.at[i,col] = df.at[i,col]*(-0.5)\n",
    "                    df.at[df.shape[0]-1, col][0] += 1\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            #check if data point has text in it. If it does, then calling float will give an error. \n",
    "            #increment the TR counter one.\n",
    "            try: \n",
    "                float(df.at[i,col])\n",
    "\n",
    "            except:\n",
    "                df.at[i,col] = np.NaN\n",
    "                df.at[df.shape[0]-1, col][3] += 1\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "\n",
    "#format the comments section with descriptions.\n",
    "\n",
    "for col in df.columns:\n",
    " \n",
    "    df.at[df.shape[0]-1, col][0] = \"NR = {}\".format(df.at[df.shape[0]-1, col][0])\n",
    "    df.at[df.shape[0]-1, col][1] = \"ZR = {}\".format(df.at[df.shape[0]-1, col][1])\n",
    "    df.at[df.shape[0]-1, col][2] = \"LTR = {}\".format(df.at[df.shape[0]-1, col][2])\n",
    "    df.at[df.shape[0]-1, col][3] = \"TR = {}\".format(df.at[df.shape[0]-1, col][3])\n",
    "\n",
    "print('Numerical transformations complete!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Data Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the module below to select the folder for storing the figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "folder_selected = filedialog.askdirectory()\n",
    "\n",
    "print(\"Folder Selected: \" + folder_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, there are three different inputs:\n",
    "\n",
    "1. Enter the column that you would like the data plotted against.\n",
    "2. Enter the elements to be plotted on a linear scale (enter end when finished.)\n",
    "3. Enter the elements to be plotted on a log scale (enter end when finished.)\n",
    "\n",
    "Please ensure that the rows begin with the element and are followed by an underscore. <br>\n",
    "Example: cu_ppm_ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_elements = [] \n",
    "lin_elements = []\n",
    "cur_in = ''\n",
    "\n",
    "rock_type = input('Enter row to be plotted against data: ')\n",
    "\n",
    "print('Enter elements to be plotted on a linear scale.')\n",
    "while True:\n",
    "    cur_in = input('Enter element:')\n",
    "    if cur_in == 'end':\n",
    "        break\n",
    "    else:\n",
    "        lin_elements.append(cur_in + '_')\n",
    "\n",
    "print('Enter elements to be plotted on a log scale.')\n",
    "while True:\n",
    "    cur_in = input('Enter element:')\n",
    "    if cur_in == 'end':\n",
    "        break\n",
    "    else:\n",
    "        log_elements.append(cur_in + '_')\n",
    "\n",
    "print(\"Elements to be graphed on a linear scale:{}\".format(lin_elements))\n",
    "print(\"Elements to be graphed on a log scale:{}\".format(log_elements))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figures are ready to be generated! Run the module below and the figures will be saved to your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking only the first rock type from the aligned_ro row to be analyzed.\n",
    "import matplotlib.style as style \n",
    "sns.set(context = 'paper') \n",
    "\n",
    "\n",
    "#parsing the  column so that only the first rock type is used. E.G. for (basalt, dacite) only basalt would be used. \n",
    "for i in range(df.shape[0]-1):   \n",
    "    if ',' in df.at[i, rock_type]:\n",
    "        comma_index = df.at[i, rock_type].find(',')\n",
    "        df.at[i, rock_type] = df.at[i, rock_type][:comma_index-1]\n",
    "\n",
    "# Making a copy of the dataframe that doesn't contain the comments row. This is done so the columns may be graphed \n",
    "# without raising datatype errors. \n",
    "df_no_comments = df.copy()\n",
    "df_no_comments = df_no_comments.drop(df.shape[0]-1)\n",
    "\n",
    "# finding all columms in the dataframe which begin with the elements to be graphed. \"_\" is added so that only the \n",
    "# element columns are found. \n",
    "\n",
    "\"\"\"log_elements = ['ag_','as_','au_','be_','bi_','cd_','co_','cr_','cu_','ge_','hf_','hg_','in_','la_','mo_','ni_',\\\n",
    "         'pb_','pd_','pt_','rb_','re_','sb_','se_','sr_','ta_','te_','th_','ti_','u_','v_','w_','y_','zn_','zr_']\n",
    "lin_elements = ['al_','b_','ba_','ca_','ce_','cs_','fe_','ga_','k_','li_',\"mg_\",'mn_','na_','nb_','p_','rb_',\\\n",
    "                's_','sc_','sn_','ti_']\"\"\"\n",
    "\n",
    "log_col = []  #contains all columns to be plotted with a log scale.\n",
    "lin_col = []  #contains all columns to be plotted with a lin scale. \n",
    "\n",
    "for col in df_no_comments.columns:\n",
    "    if col[:2] in log_elements or col[:3] in log_elements:\n",
    "        log_col.append(col)\n",
    "for col in df_no_comments.columns:\n",
    "    if col[:2] in lin_elements or col[:3] in lin_elements:\n",
    "        lin_col.append(col)\n",
    "\n",
    "\n",
    "rocks = [] # Contains one of each rock type. This is done so that the rock types can be shown on the plots in alphabetical order. \n",
    "for x in df_no_comments['aligned_ro']:\n",
    "    if x not in rocks:\n",
    "        rocks.append(x)\n",
    "\n",
    "print('Making linear figures...')\n",
    "\n",
    "for col in df_no_comments.columns:\n",
    "    if col in lin_col:\n",
    "        \n",
    "    \n",
    "        plt.figure(figsize=(200,200))\n",
    "        plt.title(\"{} - By Grouped Rock Type\".format(col), fontsize =300)\n",
    "        a = sns.boxplot(pd.to_numeric(df_no_comments[col]), df_no_comments[rock_type], order = sorted(rocks), palette = 'muted')\n",
    "        a.tick_params(labelsize=200)\n",
    "        a.set_xlabel(col ,fontsize= 300)\n",
    "        a.set_ylabel(rock_type , fontsize=300)\n",
    "        plt.tight_layout()\n",
    "        path = folder_selected + \"/\" + col\n",
    "        a.get_figure().savefig(path)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "print('Making log figures...')\n",
    "\n",
    "for col in df_no_comments.columns:\n",
    "    if col in log_col:\n",
    "       \n",
    "        plt.figure(figsize=(150,200))\n",
    "        plt.title(\"{} - By Grouped Rock Type\".format(col), fontsize =300)\n",
    "        a = sns.boxplot(pd.to_numeric(df_no_comments[col]), df_no_comments[rock_type], order = sorted(rocks), palette = 'muted')\n",
    "        a.tick_params(labelsize=200)\n",
    "        a.set_xlabel(col ,fontsize= 300)\n",
    "        a.set_ylabel(rock_type , fontsize=300)\n",
    "        path = folder_selected + \"/\" + col\n",
    "        a.get_figure().savefig(path)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "print('Done ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
